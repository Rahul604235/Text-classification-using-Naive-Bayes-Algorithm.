{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes Classifier\n",
    "\n",
    "Bayes classifiers fall under the class of **generative classifiers**. Generative classifiers attempt to learn the generation process of a dataset, usually by making some assumptions about the process that generates the data. Then such classifiers use the learned model to make a prediction or classify the unseen data. A simple example is a Naïve Bayes Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naïve Bayes classifier\n",
    "Consider a dataset $\\left\\{X^{(i)}, Y^{(i)}\\right\\}_{i=1}^{m}$. Each $X^{(i)}$ is an $n-$dimensional vector of input features. Let $Y^{(i)} \\in \\{0,1\\}$ denote the class to which $X^{(i)}$ belongs (this can be easily extended to multi-class problems as well). A good classifier has to accurately predict the probability that any given input $X$ falls in class $1$ which is $ P(Y=1 | X)$. \n",
    "\n",
    "Recall Bayes theorem,\n",
    "\n",
    "\\begin{align}\n",
    "P(Y|X) &= \\frac{P(X|Y)P(Y)}{P(X)} \\\\\n",
    "       &= \\frac{P(X_1, X_2, \\dots, X_n | Y)P(Y)}{P(X_1, X_2, \\dots, X_n)}\\\\\n",
    "\\end{align}\n",
    "\n",
    "**We use the assumption that features are independent of each other. That is one particular feature does not affect any other feature. Of course these assumptions of independence are rarely true, which is why the model is referred as the \"Naïve Bayes\" model. However, in practice, Naïve Bayes models have performed surprisingly well even on complex tasks, where it is clear that the strong independence assumptions are false.**\n",
    "\n",
    "The independence assumption reduces the conditional probability expression to\n",
    "\\begin{align}\n",
    "P(Y|X) &= \\frac{P(X_1 | Y)P(X_2 | Y) \\dots P(X_n | Y)P(Y)}{P(X_1)P(X_2)\\dots P(X_n)}\\\\\n",
    "\\end{align}\n",
    "\n",
    "The terms $P(X_i|Y)$ and $P(X_i)$ can be easily estimated/learned from the dataset. Hence, the value of $P(Y|X)$ can be found for each value of $Y$. Finally, the class to which $X$ belongs is estimated as $arg\\max_{Y}P(Y|X)$. Moreover since $X$ is independent of $Y$, it is only required to find $arg\\max_{Y}P(X|Y)P(Y).$ For better understanding with an example refer [this](https://towardsdatascience.com/naive-bayes-classifier-81d512f50a7c) article.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem statement and Dataset\n",
    "In this problem, you would implement, train and test a Naïve Bayes model to learn to classify sentiment (positive/negative) of a given text. The training data is in `all_sentiment_shuffled.txt` file.  You can use the function given below to read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk, numpy, warnings, libraries were used here.\n",
    "import nltk\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code reads the corpus file and separates them into text and label.\n",
    "def read_corpus(corpus_file):\n",
    "    \"\"\" This function reads the file in the location specified by string \n",
    "    `corpus_file` and returns a list of tuples (list of words in text, label)\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    with open(corpus_file,encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            tokens = line.strip().split()\n",
    "            out.append((tokens[3:], tokens[1]))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example:\n",
      "  Text:  ['i', 'was', 'misled', 'and', 'thought', 'i', 'was', 'buying', 'the', 'entire', 'cd', 'and', 'it', 'contains', 'one', 'song'] \n",
      "  Label:  neg\n",
      "Total number of documents = 11914\n"
     ]
    }
   ],
   "source": [
    "#function is called and spliied into text and label.\n",
    "corpus = read_corpus('./all_sentiment_shuffled.txt')\n",
    "print(\"Example:\\n\", \" Text: \", corpus[1][0], \"\\n  Label: \", corpus[1][1])\n",
    "print(\"Total number of documents =\", len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing a text document\n",
    "We can guess that not all the words in a document will be helpful in classification. The words such as \"a\", \"the\", \"is\", etc appear in all the documents randomly and can be neglected or removed. Also a same word can be written in different tenses while conveying the same mood (example \"rot\"/\"rotten\"). Hence the documents need to be preprocessed before using them for training the classifier.\n",
    "\n",
    " Libraries such as `gensim`, `nltk` contain functions for doing these preprocessing steps, and you are welcome to use such functions in your code. Formally, these are the preprocessings to be done to the input text to make them simpler and which can improve the performance of your model as well.\n",
    "* **Tokenization**: \n",
    "    1.   Split the text into sentences and the sentences into words\n",
    "    2.   Lowercase the words and remove punctuation\n",
    "* Remove all **stopwords** (stopwords are commonly used word such as \"the\", \"a\", \"an\", \"in\")\n",
    "* Remove all words that have fewer than 3 characters.\n",
    "* **Lemmatize** the document (words in third person are changed to first person, and verbs in past and future tenses are changed into present).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Removes all the punctuations present in the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Following was imported from nltk for preprocessing.\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Removes all the punctuations present in the document\n",
    "def remove_punctuation(doc,n):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    punc_removed=tokenizer.tokenize(\" \".join(doc[n][0]))\n",
    "    \n",
    "    return punc_removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Removes words like 'if', 'he', 'she', 'the', etc which never belongs to any topic and Remove all words that have fewer than 3 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes words like 'if', 'he', 'she', 'the', etc which never belongs to any topic and Remove all words that have fewer than 3 characters.\n",
    "def remove_stopwords(doc):\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    word_tokens = word_tokenize(\" \".join(doc))\n",
    "   \n",
    "    filtered_sentence = [] \n",
    "  \n",
    "    for w in word_tokens: \n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w.lower()) \n",
    "            \n",
    "    filtered_sentence=[l for l in filtered_sentence if len(l)>=3]\n",
    "    \n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " lemmatizer is a transformers which transforms the word to its singular, present-tense form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatizer is a transformers which transforms the word to its singular, present-tense form\n",
    "def lemmatize(doc):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatizer_sentence=[lemmatizer.lemmatize(w)for w in doc]\n",
    "    \n",
    "    return lemmatizer_sentence\n",
    "#nltk.download('wordnet') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to preprocess a single document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All the functions are combined together into a single preprocessing document.\n",
    "def preprocess(doc,n):\n",
    "    processed_doc = remove_punctuation(doc,n)\n",
    "    processed_doc = remove_stopwords(processed_doc)\n",
    "    processed_doc = lemmatize(processed_doc)\n",
    "    return processed_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of Naïve Bayes \n",
    "\n",
    "You can refer the Naïve Bayes section in [this](https://web.stanford.edu/~jurafsky/slp3/slides/7_NB.pdf) slides (slide #32 has a simple pseudo code) to get a hint about implementation of Naïve Bayes for text classification. Then complete the following functions `train_nb` and `classify_nb`.\n",
    "\n",
    "NOTE: If you multiply many small probabilities you may run into problems with numeric precision: the probability becomes zero. To handle this problem, it is recommended that you compute the logarithms of the probabilities instead of the probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split\n",
    "After reading the dataset, you must split the dataset into training ($80\\%$) and test data ($20\\%$). Use training data to train the Naïve Bayes classifier and use test data to check the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating testing and training datasets.\n",
    "import random\n",
    "#80 percent of the data is used for training.\n",
    "test=round(0.8*len(corpus))\n",
    "rang=len(corpus)\n",
    "training_data = random.sample(range(0,rang), test)\n",
    " \n",
    "#20 percent of the data is used for testing.    \n",
    "testing_data=[]\n",
    "for i in range(0,rang):\n",
    "    if i in training_data:\n",
    "        continue\n",
    "    else:\n",
    "        testing_data.append(i)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the probability of positive,negative statement,words.\n",
    "#This code helps in finding the probability of positive  and negative statements and classify words accordingly.\n",
    "positive=0\n",
    "negative=0\n",
    "positive_words=[]\n",
    "negative_words=[]\n",
    "for train_data in training_data:\n",
    "    if corpus[train_data][1]=='neg':\n",
    "        negative += 1\n",
    "        modin=preprocess(corpus,train_data)\n",
    "        for i in modin:\n",
    "            negative_words.append(i)\n",
    "        \n",
    "    else:\n",
    "        positive +=1 \n",
    "        modip=preprocess(corpus,train_data)\n",
    "        for j in modip:\n",
    "            positive_words.append(j)\n",
    "        \n",
    "\n",
    "#This is the probability of postive and negative statements.\n",
    "Prob_pos=positive/len(training_data)\n",
    "Prob_neg=negative/len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5049837372783549"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is the probability of postive statements.\n",
    "Prob_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4950162627216452"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is the probability of negative statements.\n",
    "Prob_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#laplace smoothing technique is considered here and with alpha=0.\n",
    "def lap_smo(Nxw,Nw,d):\n",
    "    return (Nxw+1)/(Nw+d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here d signifies the total number of unique words both in postive and negative words list.\n",
    "d=len(set(positive_words))+len(set(negative_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51309"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here d signifies the total number of unique words both in postive and negative words list.\n",
    "d=len(set(positive_words))+len(set(negative_words))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#positive words count in dictionary.\n",
    "postive_words_set=set(positive_words)\n",
    "positive_dict={}\n",
    "for dict_num1 in postive_words_set:\n",
    "    count_num1=positive_words.count(dict_num1)\n",
    "    positive_dict.update({dict_num1: count_num1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#negative words count in dictionary.\n",
    "negative_words_set=set(negative_words)\n",
    "negative_dict={}\n",
    "for dict_num2 in negative_words_set:\n",
    "    count_num2=negative_words.count(dict_num2)\n",
    "    negative_dict.update({dict_num2: count_num2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code helps in classifying a given statement into positive and negative label.\n",
    "npo=len(positive_words)\n",
    "nne=len(negative_words)\n",
    "\n",
    "result=[]\n",
    "#The the code is runing for only 100 testing data_set i have not included all because of the large computation time it takes.\n",
    "#we test for all testing data by removing [0:100].\n",
    "for test_data in testing_data:\n",
    "    \n",
    "    prob_p_x=1\n",
    "    prob_n_x=1\n",
    "    \n",
    "    mod=preprocess(corpus,test_data)\n",
    "    \n",
    "    for i in mod:\n",
    "        if i in postive_words_set:\n",
    "            tmp_p=positive_dict[i]\n",
    "            tmp_p=lap_smo(tmp_p,npo,d)\n",
    "            prob_p_x *= np.log10(tmp_p)\n",
    "        else:\n",
    "            tm_p=0\n",
    "            tmp_p=lap_smo(tmp_p,npo,d)\n",
    "            prob_p_x *= np.log10(tmp_p)\n",
    "            \n",
    "    \n",
    "    for j in mod:\n",
    "        if j in negative_words_set:\n",
    "            tmp_n=negative_dict[j]\n",
    "            tmp_n=lap_smo(tmp_n,nne,d)\n",
    "            prob_n_x *= np.log10(tmp_n)\n",
    "        else:\n",
    "            tmp_n=0\n",
    "            tmp_n=lap_smo(tmp_n,nne,d)\n",
    "            prob_n_x *= np.log10(tmp_n)\n",
    "            \n",
    "      \n",
    "    prob_p_x=abs(prob_p_x*np.log10(Prob_pos))\n",
    "    prob_n_x=abs(prob_n_x*np.log10(Prob_neg))\n",
    "    \n",
    "    if prob_p_x < prob_n_x:\n",
    "        result.append(1)\n",
    "  \n",
    "    else:\n",
    "        result.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2383"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This gives the total number of testing statements.\n",
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code helps in finding accuracy of the above model.\n",
    "compare=[]\n",
    "#The the code is runing for only 100 testing data_set i have not included all because of the large computation time it takes.\n",
    "#we test for all testing data by removing [0:100].\n",
    "for test_data in testing_data:\n",
    "    if corpus[test_data][1]=='pos':\n",
    "        compare.append(1)\n",
    "    else:\n",
    "        compare.append(-1)\n",
    "        \n",
    "accu=np.array(result)+np.array(compare)\n",
    "\n",
    "accuracy=list(accu).count(0)/len(result)\n",
    "accuracy=(1-accuracy)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.86445656735208"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is the accuracy value.\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation and Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model above constructed is 80.86445656735208 % accurate\n"
     ]
    }
   ],
   "source": [
    "#This is the final accuracy result.\n",
    "print('The model above constructed is {} % accurate'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
